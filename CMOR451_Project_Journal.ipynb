{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b70420",
   "metadata": {},
   "source": [
    " Metropolis–Hastings for Taxi Matchings (CMOR 451 Project)\n",
    " \n",
    " Metropolis–Hastings (MH) simulation where:\n",
    " \n",
    " - **States** are matchings between riders and drivers.\n",
    " - **Utility** of a matching is:  $$U(M) = \\log \\mathbb{P}\\big(\\max_i T_i(M) \\le \\text{time\\_threshold}\\big),$$  where $T_i(M)$ is the total time (pickup + trip) for rider $i$.\n",
    " \n",
    " - Pickup and trip times are modeled as **lognormal** random variables, so total time is a **sum of lognormals** and we approximate the CDF via Monte Carlo.\n",
    " - The **target distribution** over matchings is  $$\\pi(M) \\propto e^{U(M)}.$$\n",
    " \n",
    " - We also compute **CVaR** of the mean rider time as a risk / dissatisfaction measure,  and optionally penalize high CVaR in the utility.\n",
    " \n",
    " - Proposals with very long pickup distances are rejected with probability 0. Run MH under multiple (time threshold, CVaR threshold) configurations and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80463b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_data(path, n_rows=100000, seed=0):\n",
    "    \"\"\"\n",
    "    Load a subset of the taxi dataset.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df = pd.read_csv(path, nrows=n_rows)\n",
    "\n",
    "    # Clean durations: keep trips between 30 seconds and 2 hours\n",
    "    df = df[(df[\"trip_duration\"] > 30) & (df[\"trip_duration\"] < 7200)]\n",
    "\n",
    "    # Drop rows with missing coordinates\n",
    "    df = df.dropna(subset=[\n",
    "        \"pickup_longitude\", \"pickup_latitude\",\n",
    "        \"dropoff_longitude\", \"dropoff_latitude\"\n",
    "    ])\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# I feel like this is a more accurate way to calculate distance but I feel like simple distance calculation is fine for this project also lol\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Compute great-circle distance between two points (in km). Uses the haversine formula on a sphere.\n",
    "    \"\"\"\n",
    "    R = 6371.0\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (\n",
    "        np.sin(dlat / 2.0) ** 2\n",
    "        + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    )\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb255708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>3/14/2016 17:24</td>\n",
       "      <td>3/14/2016 17:32</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>6/12/2016 0:43</td>\n",
       "      <td>6/12/2016 0:54</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>1/19/2016 11:35</td>\n",
       "      <td>1/19/2016 12:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>4/6/2016 19:32</td>\n",
       "      <td>4/6/2016 19:39</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>3/26/2016 13:30</td>\n",
       "      <td>3/26/2016 13:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id  pickup_datetime dropoff_datetime  passenger_count  \\\n",
       "0  id2875421          2  3/14/2016 17:24  3/14/2016 17:32                1   \n",
       "1  id2377394          1   6/12/2016 0:43   6/12/2016 0:54                1   \n",
       "2  id3858529          2  1/19/2016 11:35  1/19/2016 12:10                1   \n",
       "3  id3504673          2   4/6/2016 19:32   4/6/2016 19:39                1   \n",
       "4  id2181028          2  3/26/2016 13:30  3/26/2016 13:38                1   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.982155        40.767937         -73.964630         40.765602   \n",
       "1        -73.980415        40.738564         -73.999481         40.731152   \n",
       "2        -73.979027        40.763939         -74.005333         40.710087   \n",
       "3        -74.010040        40.719971         -74.012268         40.706718   \n",
       "4        -73.973053        40.793209         -73.972923         40.782520   \n",
       "\n",
       "  store_and_fwd_flag  trip_duration  \n",
       "0                  N            455  \n",
       "1                  N            663  \n",
       "2                  N           2124  \n",
       "3                  N            429  \n",
       "4                  N            435  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chnage this to be relative path later\n",
    "taxi_path = \"C:\\\\Users\\\\Ethan\\\\Desktop\\\\NYCTaxiData.csv\"\n",
    "\n",
    "df = load_taxi_data(taxi_path, n_rows=100000, seed=42)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7995ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global lognormal params for trip_duration:\n",
      "  mu    = 6.470\n",
      "  sigma = 0.742\n"
     ]
    }
   ],
   "source": [
    "dur = df[\"trip_duration\"].to_numpy().astype(float)\n",
    "\n",
    "# I'm not sure if we still need to filter durations since we want to focus on all trips\n",
    "# dur = dur[(dur > 30) & (dur < 7200)]\n",
    "\n",
    "log_dur = np.log(dur)\n",
    "trip_mu_global = log_dur.mean()\n",
    "trip_sigma_global = log_dur.std()\n",
    "\n",
    "print(f\"Global lognormal params for trip_duration:\")\n",
    "print(f\"  mu    = {trip_mu_global:.3f}\")\n",
    "print(f\"  sigma = {trip_sigma_global:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2289553</td>\n",
       "      <td>2</td>\n",
       "      <td>3/28/2016 9:20</td>\n",
       "      <td>3/28/2016 9:32</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.988342</td>\n",
       "      <td>40.731522</td>\n",
       "      <td>-74.003029</td>\n",
       "      <td>40.749149</td>\n",
       "      <td>N</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2180361</td>\n",
       "      <td>1</td>\n",
       "      <td>3/11/2016 18:20</td>\n",
       "      <td>3/11/2016 18:48</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.993576</td>\n",
       "      <td>40.747108</td>\n",
       "      <td>-73.996223</td>\n",
       "      <td>40.711433</td>\n",
       "      <td>N</td>\n",
       "      <td>1683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id2195923</td>\n",
       "      <td>2</td>\n",
       "      <td>6/7/2016 12:40</td>\n",
       "      <td>6/7/2016 13:24</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.959671</td>\n",
       "      <td>40.779652</td>\n",
       "      <td>-73.970421</td>\n",
       "      <td>40.754341</td>\n",
       "      <td>N</td>\n",
       "      <td>2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id1890768</td>\n",
       "      <td>2</td>\n",
       "      <td>6/7/2016 21:48</td>\n",
       "      <td>6/7/2016 21:58</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.965469</td>\n",
       "      <td>40.765938</td>\n",
       "      <td>-73.982124</td>\n",
       "      <td>40.771385</td>\n",
       "      <td>N</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id3101055</td>\n",
       "      <td>2</td>\n",
       "      <td>2/7/2016 15:07</td>\n",
       "      <td>2/7/2016 15:11</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.978096</td>\n",
       "      <td>40.741798</td>\n",
       "      <td>-73.987595</td>\n",
       "      <td>40.735756</td>\n",
       "      <td>N</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id  pickup_datetime dropoff_datetime  passenger_count  \\\n",
       "0  id2289553          2   3/28/2016 9:20   3/28/2016 9:32                6   \n",
       "1  id2180361          1  3/11/2016 18:20  3/11/2016 18:48                2   \n",
       "2  id2195923          2   6/7/2016 12:40   6/7/2016 13:24                1   \n",
       "3  id1890768          2   6/7/2016 21:48   6/7/2016 21:58                1   \n",
       "4  id3101055          2   2/7/2016 15:07   2/7/2016 15:11                6   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.988342        40.731522         -74.003029         40.749149   \n",
       "1        -73.993576        40.747108         -73.996223         40.711433   \n",
       "2        -73.959671        40.779652         -73.970421         40.754341   \n",
       "3        -73.965469        40.765938         -73.982124         40.771385   \n",
       "4        -73.978096        40.741798         -73.987595         40.735756   \n",
       "\n",
       "  store_and_fwd_flag  trip_duration  \n",
       "0                  N            713  \n",
       "1                  N           1683  \n",
       "2                  N           2606  \n",
       "3                  N            614  \n",
       "4                  N            230  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_matching_scenario(df, n_riders=8, n_drivers=12, seed=0):\n",
    "    \"\"\"\n",
    "    Build a small matching scenario from the taxi data.\n",
    "\n",
    "    - Riders: random trips acting as customers needing a ride.\n",
    "    - Drivers: random pickup locations acting as driver starting points.\n",
    "\n",
    "    Returns a dictionary with coordinates and trip durations.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Sample riders\n",
    "    rider_idx = rng.choice(len(df), size=n_riders, replace=False)\n",
    "    riders = df.loc[rider_idx].reset_index(drop=True)\n",
    "\n",
    "    # Sample drivers\n",
    "    driver_idx = rng.choice(len(df), size=n_drivers, replace=False)\n",
    "    drivers = df.loc[driver_idx].reset_index(drop=True)\n",
    "\n",
    "    rider_pickup_lon = riders[\"pickup_longitude\"].to_numpy()\n",
    "    rider_pickup_lat = riders[\"pickup_latitude\"].to_numpy()\n",
    "\n",
    "    driver_lon = drivers[\"pickup_longitude\"].to_numpy()\n",
    "    driver_lat = drivers[\"pickup_latitude\"].to_numpy()\n",
    "\n",
    "    trip_durations = riders[\"trip_duration\"].to_numpy().astype(float)\n",
    "\n",
    "    scenario = {\n",
    "        \"riders\": riders,\n",
    "        \"drivers\": drivers,\n",
    "        \"rider_pickup_lon\": rider_pickup_lon,\n",
    "        \"rider_pickup_lat\": rider_pickup_lat,\n",
    "        \"driver_lon\": driver_lon,\n",
    "        \"driver_lat\": driver_lat,\n",
    "        \"trip_durations\": trip_durations,\n",
    "    }\n",
    "    return scenario\n",
    "\n",
    "\n",
    "scenario = build_matching_scenario(df, n_riders=8, n_drivers=12, seed=123)\n",
    "scenario[\"riders\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82b634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.25966189,  4.59917563,  5.49901929,  1.64436676,  1.77315342,\n",
       "        19.7130805 ,  5.73314536,  3.16289985,  6.07265421,  1.89188892,\n",
       "         1.18447048,  3.46778009],\n",
       "       [ 2.48794957,  3.45909978,  4.30580767,  1.47011132,  3.26120568,\n",
       "        21.00833713,  4.51059539,  1.38111491,  4.46278141,  3.14259886,\n",
       "         0.64903425,  4.89261395],\n",
       "       [ 3.23540596,  1.29408001,  0.43225979,  4.27631448,  7.62839584,\n",
       "        21.15776108,  0.19752579,  3.76364514,  1.74510266,  7.63657473,\n",
       "         5.15321438,  9.32380824],\n",
       "       [ 2.57059348,  0.31485165,  1.21457763,  2.67665892,  6.04990611,\n",
       "        20.43840181,  1.45137878,  2.63210086,  2.46399437,  6.08224257,\n",
       "         3.64490846,  7.74677435],\n",
       "       [ 3.40934363,  3.19959103,  4.09962055,  0.21338492,  3.2034454 ,\n",
       "        19.59778348,  4.33845436,  2.45017039,  4.8771224 ,  3.30790231,\n",
       "         1.33947334,  4.8944472 ],\n",
       "       [ 3.61999641,  4.72447128,  5.58680149,  2.20959174,  2.12201557,\n",
       "        21.00334649,  5.79665769,  2.52755578,  5.72252617,  1.90771876,\n",
       "         0.79318423,  3.66168083],\n",
       "       [ 2.20735695,  2.820208  ,  3.67584312,  1.19625063,  3.7515456 ,\n",
       "        20.80304942,  3.88540661,  1.19786311,  3.96824079,  3.68763301,\n",
       "         1.17062924,  5.4192526 ],\n",
       "       [ 3.61639527,  4.04310512,  4.93837635,  1.20283957,  2.33380117,\n",
       "        20.06635066,  5.16724694,  2.52517822,  5.43445205,  2.35877051,\n",
       "         0.63023113,  4.02693293]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lognormal_params_from_mean_cv(mean, cv):\n",
    "    \"\"\"Given desired mean and coefficient of variation (std/mean),\n",
    "    return (mu, sigma) for the underlying Normal of a LogNormal.\n",
    "    \"\"\"\n",
    "    # Use a CV bc it's easier to specify than stddev allowing scale-invariant variability\n",
    "    variance = (cv * mean) ** 2\n",
    "    sigma2 = np.log(1.0 + variance / (mean ** 2))\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    mu = np.log(mean) - 0.5 * sigma2\n",
    "    return mu, sigma\n",
    "\n",
    "\n",
    "def sample_lognormal(mu, sigma, size, rng):\n",
    "    \"\"\"Sample from LogNormal(mu, sigma^2) where mu, sigma are Normal parameters.\"\"\"\n",
    "    return np.exp(rng.normal(mu, sigma, size=size))\n",
    "\n",
    "\n",
    "def build_edge_time_parameters(\n",
    "    scenario,\n",
    "    trip_mu_global,\n",
    "    trip_sigma_global,\n",
    "    avg_speed_kmph=18.0,\n",
    "    pickup_cv=0.2,\n",
    "):\n",
    "    \"\"\"Build lognormal models for edge times (pickup + trip) between\n",
    "    each rider and driver.\n",
    "\n",
    "    For rider i and driver j:\n",
    "      total time T_ij = pickup_ij + trip_i\n",
    "    where pickup_ij and trip_i are both lognormals.\n",
    "\n",
    "    - trip_i uses global lognormal parameters from the data.\n",
    "    - pickup_ij has mean = distance(i,j) / avg_speed, with CV = pickup_cv.\n",
    "    \"\"\"\n",
    "    rider_lon = scenario[\"rider_pickup_lon\"]\n",
    "    rider_lat = scenario[\"rider_pickup_lat\"]\n",
    "    driver_lon = scenario[\"driver_lon\"]\n",
    "    driver_lat = scenario[\"driver_lat\"]\n",
    "\n",
    "    n_riders = len(rider_lon)\n",
    "    n_drivers = len(driver_lon)\n",
    "\n",
    "    # Distance matrix (km) rider i -> driver j\n",
    "    dist_km = np.zeros((n_riders, n_drivers))\n",
    "    for i in range(n_riders):\n",
    "        dist_km[i, :] = haversine(\n",
    "            np.full(n_drivers, rider_lon[i]),\n",
    "            np.full(n_drivers, rider_lat[i]),\n",
    "            driver_lon,\n",
    "            driver_lat,\n",
    "        )\n",
    "\n",
    "    # Mean pickup times (seconds)\n",
    "    mean_pickup_sec = (dist_km / avg_speed_kmph) * 3600.0\n",
    "\n",
    "    # Trip time lognormal params (same for all riders in this simple version)\n",
    "    trip_mu = np.full(n_riders, trip_mu_global)\n",
    "    trip_sigma = np.full(n_riders, trip_sigma_global)\n",
    "\n",
    "    # Pickup time lognormal params for each (i, j)\n",
    "    pickup_mu = np.zeros((n_riders, n_drivers))\n",
    "    pickup_sigma = np.zeros((n_riders, n_drivers))\n",
    "\n",
    "    for i in range(n_riders):\n",
    "        for j in range(n_drivers):\n",
    "            mean_ij = max(mean_pickup_sec[i, j], 10.0)  # at least 10s\n",
    "            pickup_mu[i, j], pickup_sigma[i, j] = lognormal_params_from_mean_cv(\n",
    "                mean_ij, pickup_cv\n",
    "            )\n",
    "\n",
    "    params = {\n",
    "        \"dist_km\": dist_km,\n",
    "        \"mean_pickup_sec\": mean_pickup_sec,\n",
    "        \"trip_mu\": trip_mu,\n",
    "        \"trip_sigma\": trip_sigma,\n",
    "        \"pickup_mu\": pickup_mu,\n",
    "        \"pickup_sigma\": pickup_sigma,\n",
    "    }\n",
    "    return params\n",
    "\n",
    "\n",
    "params = build_edge_time_parameters(\n",
    "    scenario,\n",
    "    trip_mu_global=trip_mu_global,\n",
    "    trip_sigma_global=trip_sigma_global,\n",
    "    avg_speed_kmph=18.0,\n",
    "    pickup_cv=0.2,\n",
    ")\n",
    "\n",
    "params[\"dist_km\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25391fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample matching log utility: -27.631021115928547\n",
      "Sample matching CVaR: 2525.8925529353432\n"
     ]
    }
   ],
   "source": [
    "def simulate_matching_times(\n",
    "    matching,\n",
    "    params,\n",
    "    time_threshold,\n",
    "    n_mc=2000,\n",
    "    alpha=0.95,\n",
    "    rng=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a matching, simulate total times and compute:\n",
    "      - Utility = log P(max_i T_i <= time_threshold)\n",
    "      - CVaR_alpha of the mean rider time\n",
    "    using Monte Carlo.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    trip_mu = params[\"trip_mu\"]\n",
    "    trip_sigma = params[\"trip_sigma\"]\n",
    "    pickup_mu = params[\"pickup_mu\"]\n",
    "    pickup_sigma = params[\"pickup_sigma\"]\n",
    "\n",
    "    n_riders = len(matching)\n",
    "\n",
    "    max_totals = np.zeros(n_mc)\n",
    "    mean_totals = np.zeros(n_mc)\n",
    "\n",
    "    for s in range(n_mc):\n",
    "        totals = np.zeros(n_riders)\n",
    "        for i in range(n_riders):\n",
    "            j = matching[i]\n",
    "            # sample pickup and trip times\n",
    "            pickup_ij = sample_lognormal(\n",
    "                pickup_mu[i, j], pickup_sigma[i, j], size=1, rng=rng\n",
    "            )[0]\n",
    "            trip_i = sample_lognormal(\n",
    "                trip_mu[i], trip_sigma[i], size=1, rng=rng\n",
    "            )[0]\n",
    "            totals[i] = pickup_ij + trip_i\n",
    "\n",
    "        max_totals[s] = totals.max()\n",
    "        mean_totals[s] = totals.mean()\n",
    "\n",
    "    # Utility\n",
    "    prob = np.mean(max_totals <= time_threshold)\n",
    "    eps = 1e-12\n",
    "    log_prob = np.log(prob + eps)\n",
    "\n",
    "    # CVaR of mean times at level alpha\n",
    "    q_alpha = np.quantile(mean_totals, alpha)\n",
    "    tail = mean_totals[mean_totals >= q_alpha]\n",
    "    if len(tail) == 0:\n",
    "        cvar = q_alpha\n",
    "    else:\n",
    "        cvar = tail.mean()\n",
    "\n",
    "    return log_prob, cvar\n",
    "\n",
    "\n",
    "# Ensure function works on a simple matching\n",
    "rng = np.random.default_rng(0)\n",
    "n_riders = len(scenario[\"riders\"])\n",
    "n_drivers = len(scenario[\"drivers\"])\n",
    "\n",
    "matching0 = np.arange(n_riders)\n",
    "log_u0, cvar0 = simulate_matching_times(\n",
    "    matching0, params, time_threshold=1800, n_mc=500, rng=rng\n",
    ")\n",
    "print(\"Sample matching log utility:\", log_u0)\n",
    "print(\"Sample matching CVaR:\", cvar0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_initial_matching(n_riders, n_drivers, rng=None):\n",
    "    \"\"\"Provide a random injective matching making sure each rider gets a unique driver.\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    drivers = np.arange(n_drivers)\n",
    "    rng.shuffle(drivers)\n",
    "    return drivers[:n_riders].copy()\n",
    "\n",
    "\n",
    "def propose_matching_swap(matching, rng=None):\n",
    "    \"\"\"\n",
    "    Symmetric proposal to pick two riders and swap their drivers.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    new_match = matching.copy()\n",
    "    i, j = rng.choice(len(matching), size=2, replace=False)\n",
    "    new_match[i], new_match[j] = new_match[j], new_match[i]\n",
    "    return new_match\n",
    "\n",
    "\n",
    "def metropolis_hastings(\n",
    "    params,\n",
    "    max_dist_km=None,\n",
    "    time_threshold=1800,\n",
    "    cvar_threshold=None,\n",
    "    # This implements the soft penalty (subtract λ * (CVaR - threshold) from log_prob) on CVaR but we can also do the hard cut off\n",
    "    cvar_penalty_weight=0.0,\n",
    "    alpha=0.95,\n",
    "    n_iters=2000,\n",
    "    burn_in=500,\n",
    "    n_mc_utility=1000,\n",
    "    seed=0,\n",
    "    hard_cvar_cutoff=False,    # if True: CVaR > threshold -> utility = -inf\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Metropolis-Hastings over matchings.\n",
    "\n",
    "    Target:\n",
    "      π(M) ∝ exp(U(M)), where U(M) is utility:\n",
    "\n",
    "        U(M) = log P(max_i T_i <= time_threshold)\n",
    "               - lambda * max(0, CVaR(M) - cvar_threshold)\n",
    "\n",
    "    Distance constraint:\n",
    "      - If max_dist_km is not None and any assigned edge exceeds it,\n",
    "        proposals are rejected immediately (transition prob 0).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    dist_km = params[\"dist_km\"]\n",
    "    n_riders, n_drivers = dist_km.shape\n",
    "\n",
    "    def feasible_by_distance(m):\n",
    "        if max_dist_km is None:\n",
    "            return True\n",
    "        d = dist_km[np.arange(n_riders), m]\n",
    "        return np.all(d <= max_dist_km)\n",
    "\n",
    "    # Initial matching\n",
    "    current = random_initial_matching(n_riders, n_drivers, rng)\n",
    "\n",
    "    # Try to find an initial feasible matching wrt distance\n",
    "    if max_dist_km is not None and not feasible_by_distance(current):\n",
    "        found = False\n",
    "        for _ in range(2000):\n",
    "            cand = random_initial_matching(n_riders, n_drivers, rng)\n",
    "            if feasible_by_distance(cand):\n",
    "                current = cand\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(\n",
    "                \"Could not find an initial matching satisfying \"\n",
    "                f\"max_dist_km={max_dist_km}. Need to disable distance constraint.\"\n",
    "            )\n",
    "\n",
    "    def apply_cvar_to_utility(log_prob, cvar):\n",
    "        if cvar_threshold is None:\n",
    "            return log_prob\n",
    "        if hard_cvar_cutoff and (cvar > cvar_threshold):\n",
    "            return -np.inf\n",
    "        if cvar_penalty_weight > 0.0:\n",
    "            excess = max(0.0, cvar - cvar_threshold)\n",
    "            return log_prob - cvar_penalty_weight * excess\n",
    "        return log_prob\n",
    "\n",
    "    # Evaluate initial state\n",
    "    current_log_prob, current_cvar = simulate_matching_times(\n",
    "        current, params, time_threshold,\n",
    "        n_mc=n_mc_utility, alpha=alpha, rng=rng,\n",
    "    )\n",
    "    current_U = apply_cvar_to_utility(current_log_prob, current_cvar)\n",
    "\n",
    "    samples = []\n",
    "    log_utils = []\n",
    "    cvars = []\n",
    "\n",
    "    for it in range(n_iters):\n",
    "        proposal = propose_matching_swap(current, rng)\n",
    "\n",
    "        # Distance-based hard constraint\n",
    "        if max_dist_km is not None and not feasible_by_distance(proposal):\n",
    "            accept = False\n",
    "        else:\n",
    "            prop_log_prob, prop_cvar = simulate_matching_times(\n",
    "                proposal, params, time_threshold,\n",
    "                n_mc=n_mc_utility, alpha=alpha, rng=rng,\n",
    "            )\n",
    "            prop_U = apply_cvar_to_utility(prop_log_prob, prop_cvar)\n",
    "\n",
    "            # MH acceptance ratio\n",
    "            log_ratio = prop_U - current_U\n",
    "            if np.isneginf(prop_U) and np.isneginf(current_U):\n",
    "                accept = False\n",
    "            elif log_ratio >= 0:\n",
    "                accept = True\n",
    "            else:\n",
    "                u = rng.uniform()\n",
    "                accept = (np.log(u) < log_ratio)\n",
    "\n",
    "        if accept:\n",
    "            current = proposal\n",
    "            current_log_prob, current_cvar = prop_log_prob, prop_cvar\n",
    "            current_U = apply_cvar_to_utility(current_log_prob, current_cvar)\n",
    "\n",
    "        if it >= burn_in:\n",
    "            samples.append(current.copy())\n",
    "            log_utils.append(current_log_prob)\n",
    "            cvars.append(current_cvar)\n",
    "\n",
    "    samples = np.array(samples)\n",
    "    log_utils = np.array(log_utils)\n",
    "    cvars = np.array(cvars)\n",
    "\n",
    "    return samples, log_utils, cvars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "Config: time_threshold=1200 sec, cvar_threshold=1500 sec\n",
      "=======================================\n",
      "Collected 600 post–burn-in samples\n",
      "Mean log utility (log P(max <= T)): -4.942\n",
      "Mean CVaR (mean time, α=0.95):      1949.1 sec\n",
      "CVaR quantiles (50%, 80%, 90%, 95%): [1935.30474884 2021.40736361 2078.43827637 2157.56572632]\n",
      "\n",
      "=======================================\n",
      "Config: time_threshold=1800 sec, cvar_threshold=2000 sec\n",
      "=======================================\n",
      "Collected 600 post–burn-in samples\n",
      "Mean log utility (log P(max <= T)): -2.160\n",
      "Mean CVaR (mean time, α=0.95):      2075.6 sec\n",
      "CVaR quantiles (50%, 80%, 90%, 95%): [2064.96491143 2174.76909008 2237.31968832 2287.76120057]\n",
      "\n",
      "=======================================\n",
      "Config: time_threshold=2400 sec, cvar_threshold=2500 sec\n",
      "=======================================\n",
      "Collected 600 post–burn-in samples\n",
      "Mean log utility (log P(max <= T)): -0.963\n",
      "Mean CVaR (mean time, α=0.95):      2151.2 sec\n",
      "CVaR quantiles (50%, 80%, 90%, 95%): [2147.16673644 2265.12579898 2322.84178368 2371.56418854]\n"
     ]
    }
   ],
   "source": [
    "# Some example configurations that chat came up with\n",
    "configs = [\n",
    "    {\"time_threshold\": 1200, \"cvar_threshold\": 1500},  # 20 min\n",
    "    {\"time_threshold\": 1800, \"cvar_threshold\": 2000},  # 30 min\n",
    "    {\"time_threshold\": 2400, \"cvar_threshold\": 2500},  # 40 min\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for cfg in configs:\n",
    "    print(\"\\n=======================================\")\n",
    "    print(f\"Config: time_threshold={cfg['time_threshold']} sec, \"\n",
    "          f\"cvar_threshold={cfg['cvar_threshold']} sec\")\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    samples, log_utils, cvars = metropolis_hastings(\n",
    "        params,\n",
    "        max_dist_km=10.0,                    # very long pickup distance\n",
    "        time_threshold=cfg[\"time_threshold\"],\n",
    "        cvar_threshold=cfg[\"cvar_threshold\"],\n",
    "        cvar_penalty_weight=0.001,           # soft CVaR penalty\n",
    "        alpha=0.95,\n",
    "        n_iters=800,                         # increase for more serious runs\n",
    "        burn_in=200,\n",
    "        n_mc_utility=500,\n",
    "        seed=0,\n",
    "        hard_cvar_cutoff=False,              # set True to hard-reject high CVaR\n",
    "    )\n",
    "\n",
    "    print(f\"Collected {len(samples)} post–burn-in samples\")\n",
    "    print(f\"Mean log utility (log P(max <= T)): {np.mean(log_utils):.3f}\")\n",
    "    print(f\"Mean CVaR (mean time, α=0.95):      {np.mean(cvars):.1f} sec\")\n",
    "\n",
    "    if len(cvars) > 0:\n",
    "        q = np.quantile(cvars, [0.5, 0.8, 0.9, 0.95])\n",
    "        print(\"CVaR quantiles (50%, 80%, 90%, 95%):\", q)\n",
    "\n",
    "    results.append((cfg, samples, log_utils, cvars))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
